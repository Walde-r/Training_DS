{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62dc16cd",
   "metadata": {},
   "source": [
    "В этом юните мы познакомимся с ещё одним семейством моделей машинного обучения — `деревьями решений`. Для начала поговорим о том, что такое дерево решений и как с его помощью решают задачу классификации.\n",
    "\n",
    "Деревья решений являются одним из наиболее понятных человеку и в то же время мощных алгоритмов принятия решений. К тому же на их основе строятся самые эффективные ансамблевые модели машинного обучения, такие как случайный лес, о котором мы поговорим далее.\n",
    "\n",
    "Алгоритмы `на основе деревьев решений` могут использоваться как `для` решения задач `классификации`, так `и` для `регрессии`. В этом модуле мы разберём задачу классификации, а в дальнейшем, когда будем разбирать математическую составляющую алгоритмов, поговорим о том, как научить дерево решать задачу регрессии.\n",
    "\n",
    "> Если коротко, решающее дерево предсказывает значение целевой переменной с помощью применения последовательности простых решающих правил. Этот процесс в некотором смысле согласуется с естественным для человека процессом принятия решений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef9f0d",
   "metadata": {},
   "source": [
    "#### ОБЩЕЕ ПРЕДСТАВЛЕНИЕ О ДЕРЕВЕ РЕШЕНИЙ\n",
    "\n",
    "Начнём сразу с примера.\n",
    "\n",
    "Представьте, что у вас есть автомобиль, который вы решили застраховать. Вы приходите в страховую компанию, где вам дают заполнить анкету. По этой анкете сотрудник страховой компании будет принимать решение, стоит ли выдавать вам страховку.\n",
    "\n",
    "Сотрудник в свою очередь будет руководствоваться примерно следующим регламентом:\n",
    "\n",
    "- Если возраст владельца > 40 лет, то:\n",
    "    - Если место эксплуатации автомобиля — город, то:\n",
    "        - Если стаж > 10 лет, то:\n",
    "            - Застраховать.\n",
    "        - Если стаж < 10 лет, то:\n",
    "            -Не страховать.\n",
    "    - Если место эксплуатации автомобиля — сельская местность, то:\n",
    "        - Застраховать.\n",
    "- Если возраст владельца ≤ 40 лет, то:\n",
    "    - Если аварий не было зафиксировано, то:\n",
    "        - Застраховать.\n",
    "    - Если были аварии, то:\n",
    "        - Если тип автомобиля — минивэн, то:\n",
    "            - Застраховать.\n",
    "        - Если тип автомобиля — спорткар, то:\n",
    "            - Не страховать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29d1c5",
   "metadata": {},
   "source": [
    "То есть сотрудник при принятии решения использует информацию, предоставленную вами в анкете, и подает её на вход вложенного условного оператора.\n",
    "\n",
    "Для простоты восприятия можно представить такой подход визуально в виде следующего дерева:\n",
    "\n",
    "<img src='img/ML_3_6_1.png'>\n",
    "\n",
    "Аналогичным образом работает и алгоритм машинного обучения под названием `«дерево решений» (Decision Tree)`. \n",
    "\n",
    "Если дерево уже обучено, то есть уже сформулированы условия в прямоугольниках, то, когда в страховую компанию придёт новый автовладелец, сотруднику будет достаточно прогнать данные клиента через дерево решений и таким образом принять решение, то есть произвести классификацию.\n",
    "\n",
    "> Вот ещё один пример дерева решений. Большинство из нас когда-нибудь играли в игру «Слова на лбу» или «Тарантинки». На лоб каждого из игроков приклеивается бумажка с написанным на ней словом. Игрок может задавать другим игрокам вопросы о загаданном ему предмете/животном/человеке и т. д. Другие игроки могут отвечать на вопросы только «Да» и «Нет». Цель — за минимальное количество вопросов догадаться, о чём идёт речь.\n",
    "\n",
    "Логика «если …, то …» используется людьми повседневно и поэтому интуитивно понятна каждому из нас. На основании этих рассуждений можно построить мощный алгоритм машинного обучения.\n",
    "\n",
    "Деревья решений находят своё применение во множестве прикладных задач.\n",
    "\n",
    "Успешнее всего деревья применяют в следующих областях:\n",
    "\n",
    "- Банковское дело. Оценка кредитоспособности клиентов банка при выдаче кредитов.\n",
    "- Промышленность. Контроль качества продукции (обнаружение дефектов в готовых товарах), испытания без нарушений (например, проверка качества сварки) и т. п.\n",
    "- Медицина. Диагностика заболеваний разной сложности.\n",
    "- Молекулярная биология. Анализ строения аминокислот.\n",
    "- Торговля. Классификация клиентов и товара."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307092e3",
   "metadata": {},
   "source": [
    "Теперь перейдём к формальной части. Нам важно уже сейчас познакомиться с терминологией деревьев решений, чтобы понять общий принцип их обучения.\n",
    "\n",
    "Пусть у нас есть всё та же матрица наблюдений `X`, в которой содержатся наблюдения и характеризующие их признаки (привычный нам DataFrame), и правильные ответы `y` — метки классов. \n",
    "\n",
    "Дадим определение дереву решений и его составляющим\n",
    "\n",
    "Формально структура дерева решений — это **связный ациклический граф**. Что это значит?\n",
    "\n",
    "**Граф** — это абстрактная топологическая модель, которая состоит из вершин и соединяющих их рёбер.\n",
    "\n",
    "**Связный граф** — это граф, в котором между любой парой существует направленная связь.\n",
    "\n",
    "**Ациклический граф** — это граф, в котором отсутствуют циклы, то есть в графе не существует такого пути, по которому можно вернуться в начальную вершину.\n",
    "\n",
    "<img src='img/ML_3_6_2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd16348",
   "metadata": {},
   "source": [
    "В дереве решений можно выделить три типа вершин:\n",
    "\n",
    "<img src='img/ML_3_6_3.png'>\n",
    "\n",
    "`Корневая вершина (root node)` — то, откуда всё начинается. Это первый и самый главный вопрос, который дерево задаёт объекту. В примере со страхованием это был вопрос «Возраст автовладельца > 40».\n",
    "\n",
    "`Внутренние вершины (intermediate nodes)` — это дополнительные уточняющие вопросы, которые дерево задаёт объекту. \n",
    "\n",
    "`Листья (leafs)` — конечные вершины дерева. Это вершины, в которых содержится конечный «ответ» — класс объекта.\n",
    "\n",
    "> Максимально возможная длина от корня до самых дальних листьев (не включая корневую) называется максимальной глубиной дерева (max depth).\n",
    "\n",
    "Во внутренней или корневой вершине признак проверяется на некий логический критерий, по результатам которого мы движемся всё глубже по дереву. Например, «Количество кредитов $\\leq 1$ ». \n",
    "\n",
    "> Логический критерий, который находится в каждой вершине, называется `предикатом`, или `решающим правилом`.\n",
    "\n",
    "На самом деле все предикаты — это просто взятие порога по значению какого-то признака. Формально это записывается следующим образом:\n",
    "\n",
    "$$\n",
    "B_v (x,t) = I [x_j \\leq t]\n",
    "$$\n",
    "\n",
    "Предикат вершины дерева $B_v$  (где $v$  — это номер вершины) равен 1 («Да»), если признак $x_j$ меньше либо равен значению $t$, и 0 («Нет») — в противном случае. Функция $I$ с квадратными скобками — это уже знакомая нам индикаторная функция: она равна 1, если условие внутри скобок выполняется, и 0 — в противном случае.\n",
    "\n",
    "> Примечание. В зависимости от реализации предикат может быть с условием $\\leq$ или $\\geq$. В реализации `sklearn` используется условие $\\leq$. Но вы можете встретить другую формулировку предикатов в иных реализациях или в литературе.\n",
    "\n",
    "Если результат предиката равен 1, то мы переходим по левой ветви дерева к следующему узлу, в противном случае — по правой ветви дерева к следующему узлу.\n",
    "\n",
    "А что насчёт геометрии?\n",
    "\n",
    "Каждый новый вопрос дерева решений при его обучении разбивает пространство признаков на две части: в первую часть отправляются наблюдения, для которых предикат истинен, а во вторую — для которых он ложен.\n",
    "\n",
    "Посмотрим, как это будет выглядеть, на примере. \n",
    "\n",
    "Вам уже знакома задача классификации про ирисы. Ирисы Фишера — это задача, на которой Рональд Фишер ещё в 1936 году (почти 100 лет назад!) продемонстрировал работу алгоритма, разделяющего ирисы на сорта в зависимости от параметров долей околоцветника.\n",
    "\n",
    "Пусть у нас есть следующие признаки:\n",
    "\n",
    "- длина внутренней доли околоцветника (англ. petal length);\n",
    "- ширина внутренней доли околоцветника (англ. petal width).\n",
    "\n",
    "На основании этих двух признаков требуется разделить ирисы на три сорта:\n",
    "\n",
    "- ирис щетинистый (Iris Setosa);\n",
    "- ирис виргинский (Iris virginica);\n",
    "- ирис разноцветный (Iris versicolor).\n",
    "\n",
    "Пусть мы обучили на этих данных дерево решений с максимальной глубиной 2. Оно получилось вот таким:\n",
    "\n",
    "<img src='img/dst3-ml3-5_4.png'>\n",
    "\n",
    "В каждом блоке указаны следующие данные:\n",
    "\n",
    "- Предикат $I[x_j \\leq t]$ — условие, по которому выборка делится на две части: на ту, для которой условие выполняется, и ту, для которой не выполняется.\n",
    "- gini — критерий информативности Джини, о котором мы поговорим чуть позже.\n",
    "- samples — количество объектов, которые мы проверяем на данном шаге.\n",
    "- value — распределение по классам для объектов, которые мы проверяем на данном шаге: например value=[0, 50, 50] означает, что на текущем этапе разделения в выборке находится 0 объектов класса setosa и по 50 объектов классов versicolor и virginica.\n",
    "- class — класс, который мы присваиваем, если завершим выполнение алгоритма на данном шаге.\n",
    "\n",
    "А вот так будет выглядеть наш процесс разделения цветов на классы:\n",
    "\n",
    "<img src='img/dst3-ml3-5_5.png'>\n",
    "\n",
    "Как происходит построение разделяющих плоскостей?\n",
    "\n",
    "`Глубина дерева = 0.`\n",
    "\n",
    "- Дерево задаёт первый вопрос: $petal length \\leq 2.45$. Это выражение соответствует вертикальной прямой, которая делит пространство на две части по признаку `petal length`.\n",
    "\n",
    "- В левую часть пространства попали 50 наблюдений. Это только жёлтые точки пространства — цветы setosa. Значит, дальнейшее разделение не имеет смысла.\n",
    "\n",
    "- В правую часть пространства попали 100 наблюдений. Это и синие, и зелёные объекты классов versicolor и virginica. Значит, нужно попробовать задать ещё одно решающее правило.\n",
    "\n",
    "`Глубина дерева = 1.`\n",
    "\n",
    "- Дерево задаёт второй вопрос: $petal width \\leq 1.75$. Это выражение соответствует горизонтальной прямой, которая делит оставшееся после прошлого разделения пространство на две части по признаку petal width.\n",
    "\n",
    "- В нижнюю (синюю) часть этого пространства попали 54 наблюдения. Из них 49 цветов класса versicolor и 5 цветов класса virginica.\n",
    "\n",
    "- Максимальная глубина достигнута. В полученной части пространства преобладает класс versicolor, значит все наблюдения, которые находятся в этой части, дерево будет относить к классу versicolor.\n",
    "\n",
    "- В верхнюю (зелёную) часть этого пространства попали 46 наблюдений. Из них 1 цветок класса versicolor и 45 цветов класса virginica.\n",
    "\n",
    "- Максимальная глубина достигнута. В полученной части пространства преобладает класс virginica, значит все наблюдения, которые находятся в этой части, дерево будет относить к классу virginica.\n",
    "\n",
    "Отметим, что деление пространства можно продолжать до тех пор, пока пространство не будет разделено так, чтобы верно выделить каждый из классов. \n",
    "\n",
    "Кстати, для каждой области можно подсчитать вероятность каждого из классов. Это просто отношение количества объектов -класса, которые попали в лист дерева, к общему количеству объектов в листе.\n",
    "\n",
    "Например, для синей области вероятности будут равны:\n",
    "\n",
    "$$\n",
    "\\hat{P}(класс = setosa) = \\frac{0}{54} = 0 \\\\ \n",
    "\n",
    "\\hat{P}(класс = virginica) = \\frac{5}{54} = 0.09 \\\\\n",
    "\n",
    "\\hat{P}(класс = versicolor) = \\frac{49}{54} = 0.91\n",
    "$$\n",
    "\n",
    "Теперь, когда мы разобрались с терминологией и геометрией, давайте поговорим о том, как строится решающее дерево."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da16e59",
   "metadata": {},
   "source": [
    "### ПРОЦЕСС ПОСТРОЕНИЯ ДЕРЕВА РЕШЕНИЙ\n",
    "\n",
    "Cуществует множество [стратегий](https://scikit-learn.ru/1-10-decision-trees/#tree-algorithms-id3-c4-5-c5-0-and-cart) построения деревьев решений. Мы рассмотрим стратегию, реализованную в библиотеке `sklearn`, — алгоритм `CART (Classification and Regression Tree)`, который предназначен для построения бинарных деревьев решений (деревьев, у которых каждая вершина связана с двумя другими вершинами нижнего уровня). Данный алгоритм, как следует из его названия, предназначен для решения задач классификации и регрессии.\n",
    "\n",
    "Внимательный студент уже заметил, что построение дерева решений можно описать рекурсией. Каждая вершина дерева порождает две других вершины, а они в свою очередь порождают новые вершины, и так происходит до тех пор, пока не выполнится некоторый критерий остановки, например в вершине не останутся только наблюдения определённого класса.\n",
    "\n",
    "> Примечание. Если вы забыли, что такое рекурсия, рекомендуем вам вернуться к модулю `по продвинутому использованию функций` и активировать рекурсивное мышление, оно нам понадобится.\n",
    "\n",
    "Пусть у нас есть матрица наблюдений `X` и столбец с ответами — метками классов `y`. На основе примеров и ответов мы хотим построить дерево решений, которое будет производить классификацию.\n",
    "\n",
    "Итак, псевдокод рекурсивной функции для построения решающего дерева будет выглядеть следующим образом (запускать код не нужно, так как он является абстрактным):\n",
    "\n",
    "```PYTHON\n",
    "def build_decision_tree(X, y):\n",
    "    node = Node()\n",
    "    if stopping_criterion(X, y) is True:\n",
    "        node = create_leaf_with_prediction(y)\n",
    "\treturn node\n",
    "    else:\n",
    "        X_left, y_left, X_right, y_right = best_split(X, y)\n",
    "        node.left = build_decision_tree(X_left, y_left)\n",
    "        node.right = build_decision_tree(X_right, y_right)\n",
    "```\n",
    "\n",
    "Разберёмся, как работает алгоритм:\n",
    "\n",
    "1. Создать новую вершину node.\n",
    "\n",
    "На первой итерации это будет корневая вершина. На последующих это будут внутренние вершины.\n",
    "\n",
    "2. Проверить некоторый критерий остановки `stop_criterion()`.\n",
    "\n",
    "Например, критерием остановки может быть следующее условие: все объекты, которые попали в вершину, — это объекты одного и того же класса.\n",
    "\n",
    "Или достигнута максимальная глубина дерева (`max_depth`), например 5. Это значит, что дерево не будет продолжать делиться, если глубина уже равна 5.\n",
    "\n",
    "Другой критерий: число наблюдений в листе (в `sklearn` этот параметр обозначен как `min_samples_leaf`) меньше заданного, например 7. Это значит, что при выполнении такого условия дерево продолжит делиться в том случае, если решающее правило выполняется как минимум для 7 наблюдений.\n",
    "\n",
    "- 2.1  Если условие остановки выполняется:\n",
    "\n",
    "Проверить, какой класс преобладает в текущей вершине. Превратить текущую вершину дерева в лист, где всем наблюдениям, которые попали в эту вершину, присвоить метку преобладающего класса.\n",
    "\n",
    "Прекратить построение дерева, вернув из алгоритма полученный лист.\n",
    "\n",
    "- 2.2 Если условие остановки не выполняется:\n",
    "\n",
    "Среди всех возможных предикатов $B_v(x,t) = I[x_j \\leq t]$ найти такой, который обеспечивает разбиение выборки наилучшим образом.\n",
    "\n",
    "То есть нужно найти такой признак $x_j$ и пороговое значение $t$, при которых достигается максимум некоторой информативности (существуют разные меры информативности, о них поговорим ниже). Назовём эту часть алгоритма некоторой абстрактной функцией `best_split()`.\n",
    "\n",
    "Например, в нашем примере с ирисами это был предикат $Petal.Length \\leq 2.45$. Он обеспечил наилучшее разделение пространства на две части.\n",
    "\n",
    "В результате разбиения будут созданы два набора данных:\n",
    "\n",
    " - `X_left, y_left` (левый), для которого выполняется условие ;\n",
    " - `X_right, y_right` (правый), для которого условие не выполняется.\n",
    "\n",
    "Создаются две новые вершины: левая и правая, в каждую из которых отправляется соответствующий набор данных.\n",
    "\n",
    "То есть происходит рекурсивный вызов функции `build_decision_tree()`, и для каждой новой вершины алгоритм повторяется вновь с новым набором данных.\n",
    "\n",
    "> Примечание. Вершина дерева `node` задаёт целое поддерево идущих за ним вершин, если такие имеются, а не только саму вершину.\n",
    "\n",
    "Центральный момент в построении дерева решений по обучающему набору данных — найти такой предикат $B_v(x,t) = I[x_j \\leq t]$ , который обеспечит наилучшее разбиение выборки на классы. \n",
    "\n",
    "Как дерево определяет, какой вопрос нужно задать в каждой из вершин? \n",
    "\n",
    "Например, в задаче кредитного скоринга мы можем задавать множество различных вопросов в разной последовательности. Предикаты  в первой вершине могут быть различными:\n",
    "\n",
    "- возраст заёмщика $\\leq$ 25 лет,\n",
    "возраст заёмщика $\\leq$ 40 лет,\n",
    "размер кредита $\\leq$ 1000 $,\n",
    "наличие детей $\\leq$ 0.5 (если наличие детей — бинарный категориальный признак: 1 — есть дети, 0 — нет детей),\n",
    "и так далее.\n",
    "Видно, что на место $x_j$ и $t$ можно подставить любой признак и порог соответственно.\n",
    "\n",
    "Признак $x_j$ и его пороговое значение $t$ в каждой из вершин и есть внутренние параметры дерева решений, которые мы пытаемся отыскать. Это аналог коэффициентов уравнения линейной и логистической регрессий. \n",
    "\n",
    "> Какие же и в какой последовательности нужно задавать вопросы, или как подобрать оптимальные параметры дерева?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f42f97",
   "metadata": {},
   "source": [
    "### ПОИСК ПАРАМЕТРОВ ДЕРЕВА РЕШЕНИЙ\n",
    "\n",
    "> Обратите внимание, что внутренние параметры дерева решений кардинально отличаются от линейных моделей.\n",
    "\n",
    "В линейных моделях мы пытались найти такие коэффициенты в уравнениях, при которых наблюдался `минимум функции потерь`.\n",
    "\n",
    "В деревьях же мы пытаемся выбрать такие признаки $x_j$ и их пороговые значения $t$, при которых произойдёт разделение набора на две части по какому-то критерию наилучшим образом. В нашем псевдокоде этот процесс организован в виде функции `best_split()`.\n",
    "\n",
    "Важно понимать, что `дерево решений — это топологический алгоритм`, а не аналитический, то есть с`труктуру дерева не получится описать в виде формулы`, как те же линейные модели. Поэтому про стандартные методы оптимизации, такие как градиентный спуск или тем более метод наименьших квадратов, можно забыть. \n",
    "\n",
    "Чтобы интуитивно понять, как организуется поиск параметров, вспомним про игру «Слова на лбу».\n",
    "\n",
    "> Пусть один человек загадывает знаменитость, а второй пытается отгадать, задавая только вопросы, на которые можно ответить «Да» или «Нет» (опустим варианты «не знаю» и «не могу сказать»).<br>\n",
    "Какой вопрос отгадывающий задаст первым делом? Конечно, такой, который лучше всего уменьшит количество оставшихся вариантов.<br>\n",
    "К примеру, вопрос «Это Анджелина Джоли?» в случае отрицательного ответа оставит более 7.5 миллиардов вариантов для дальнейшего перебора (строго говоря, поменьше, ведь не каждый человек — знаменитость, но всё равно немало), а вот вопрос «Это женщина?» отсечёт уже около половины знаменитостей.<br>\n",
    "То есть, признак пол намного лучше разделяет выборку людей, чем признак это Анджелина Джоли, национальность — испанец или любит футбол. <br>\n",
    "Интуитивно это соответствует уменьшению некоторой неопределённости, или, иначе говоря, повышению прироста информативности.\n",
    "\n",
    "В случае «угадайки» знаменитостей критериев отбора может быть бесчисленное количество. Но когда мы работаем с набором данных, у нас ограниченное количество признаков и для них есть ограниченное количество порогов. Тогда мы можем полным перебором найти такую комбинацию $j$ и $t$, которая обеспечит наилучшее уменьшение неопределённости.\n",
    "\n",
    "Неопределённость можно измерять различными способами, в деревьях решений для этого используются **энтропия Шеннона и критерий Джини**. Мы подробно обсудим их реализацию в модулях по математике."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myConda_env_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
